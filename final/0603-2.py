import asyncio
import csv
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import pandas as pd
import os

async def get_lat_lon_from_html(route_id):
    """
    æ ¹æ“šè·¯ç·šä»£ç¢¼æŠ“å–ç«™ç‰Œçš„ç¶“ç·¯åº¦
    """
    url = f"https://ebus.gov.taipei/Route/StopsOfRoute?routeid={route_id.strip()}"
    all_stops_data = []
    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            await page.goto(url, timeout=2_000_000)  # è¨­å®šè¶…é•·timeout
            await page.wait_for_selector("div#GoDirectionRoute li, div#BackDirectionRoute li", timeout=2_000_000)
            html = await page.content()
            await browser.close()
        soup = BeautifulSoup(html, "html.parser")
        # ...åŸæœ¬çš„è³‡æ–™æ“·å–ç¨‹å¼...
        for direction_label, selector in [("å»ç¨‹", "div#GoDirectionRoute li"), ("è¿”ç¨‹", "div#BackDirectionRoute li")]:
            station_items = soup.select(selector)
            if not station_items:
                continue
            for li in station_items:
                try:
                    spans = li.select("span.auto-list-stationlist span")
                    inputs = li.select("input")
                    stop_name = spans[2].get_text(strip=True)
                    stop_id = inputs[0]['value']
                    latitude = inputs[1]['value']
                    longitude = inputs[2]['value']
                    all_stops_data.append({
                        "æ–¹å‘": direction_label,
                        "ç«™ç‰Œåç¨±": stop_name,
                        "ç«™ç‰ŒID": stop_id,
                        "ç·¯åº¦": latitude,
                        "ç¶“åº¦": longitude
                    })
                except Exception as e:
                    print(f"æŠ“å–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    except Exception as e:
        print(f"âš ï¸ è·¯ç·š {route_id} é€£ç·šå¤±æ•—æˆ–è¶…æ™‚ï¼ˆç•¥éï¼‰ï¼š{e}")
        return []
    return all_stops_data

# å„²å­˜çµæœè‡³ CSV
def save_to_csv(all_data, csv_output_path):
    with open(csv_output_path, mode="w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=["æ–¹å‘", "ç«™ç‰Œåç¨±", "ç«™ç‰ŒID", "ç·¯åº¦", "ç¶“åº¦"])
        writer.writeheader()
        writer.writerows(all_data)

# ä¸»å‡½æ•¸ï¼šéæ­·æ¯æ¢å…¬è»Šè·¯ç·šï¼ŒæŠ“å–ç¶“ç·¯åº¦ä¸¦å„²å­˜
async def main(csv_input_path, csv_output_path):
    # è®€å–è·¯ç·šè³‡æ–™
    df_routes = pd.read_csv(csv_input_path)
    all_stops_data = []

    for route_id in df_routes["è·¯ç·šä»£ç¢¼"]:
        print(f"ğŸ“¡ æ­£åœ¨æŠ“å–è·¯ç·š {route_id} çš„è³‡æ–™...")
        route_data = await get_lat_lon_from_html(route_id)
        all_stops_data.extend(route_data)

    # å„²å­˜è‡³ CSV
    save_to_csv(all_stops_data, csv_output_path)
    print(f"\n è³‡æ–™å·²å„²å­˜è‡³ï¼š{csv_output_path}")

# åŸ·è¡Œä¸»ç¨‹å¼
if __name__ == "__main__":
    csv_input_path = r"C:\Users\CYCU\Desktop\cycu_oop_11372009\final\0527\taipei_bus_routes.csv"  # è®€å–å…¬è»Šè·¯ç·šè³‡æ–™ CSV æª”
    desktop = os.path.join(os.path.expanduser("~"), "Desktop")
    csv_output_path = os.path.join(desktop, "bus_stops_with_lat_lon.csv")  # è¼¸å‡ºæª”æ¡ˆåˆ°æ¡Œé¢

    asyncio.run(main(csv_input_path, csv_output_path))
